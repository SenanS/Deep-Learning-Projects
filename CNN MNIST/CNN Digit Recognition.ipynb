{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check training will be done on GPU\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve MNIST dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure data is correct shape\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x211291fa988>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print Dataset Image\n",
    "plt.imshow(x_train[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "# Print Classes Present\n",
    "print(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Channels dimension\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\") / 255\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\") / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching data\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(16)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model subclass\n",
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.dense1 = Dense(128, activation='relu')\n",
    "    self.dense2 = Dense(10)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense1(x)\n",
    "    return self.dense2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing loss and optimiser\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.126772940158844, Accuracy: 96.13333129882812, Test Loss: 0.05416492745280266, Test Accuracy: 98.13999938964844\n",
      "Epoch 2, Loss: 0.04123436287045479, Accuracy: 98.71333312988281, Test Loss: 0.05262459069490433, Test Accuracy: 98.33999633789062\n",
      "Epoch 3, Loss: 0.019637051969766617, Accuracy: 99.40499877929688, Test Loss: 0.0526658371090889, Test Accuracy: 98.45999908447266\n",
      "Epoch 4, Loss: 0.011735953390598297, Accuracy: 99.60832977294922, Test Loss: 0.07977193593978882, Test Accuracy: 98.00999450683594\n",
      "Epoch 5, Loss: 0.008789132349193096, Accuracy: 99.69833374023438, Test Loss: 0.07477471232414246, Test Accuracy: 98.18000030517578\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for images, labels in train_ds:\n",
    "    train_step(images, labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# model.save_weights('CNN_weights/CNN_Digit_Recog_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Re-Loading model\n",
    "# validate_model = tf.keras.models.load_model('CNN_Digit_Recog_Model.h5')\n",
    "\n",
    "# # Show the model architecture\n",
    "# validate_model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
